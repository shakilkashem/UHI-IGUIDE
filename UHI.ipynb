{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a0d8d38-0c00-4604-a782-a637d08f1a74",
   "metadata": {},
   "source": [
    "---\n",
    "Modeling the relationship between urban tree canopy, land cover, and land surface temperature\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf0bc2-b98a-41e9-8fdd-b3e1963470e9",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This exercise first shows some exploratory tasks to model land surface temperature (LST) and tree canopy to explore Urban Heat Island. As [described here by NASA](https://earthobservatory.nasa.gov/global-maps/MOD_LSTD_M), \"land surface temperature is how hot the 'surface' of the Earth would feel to the touch in a particular location\". It also lays out an initial modeling approach that combines exploratory data analysis with [KNN regresson](https://towardsdatascience.com/the-basics-knn-for-classification-and-regression-c1e8a6c955) and [decision tree models](https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052) to better understand the patterns of the data and for prediction purposes in the R environment.  \n",
    "\n",
    "We will use three primary datasets. The first are [land surface temperature (LST) data](https://www.usgs.gov/centers/eros/science/usgs-eros-archive-landsat-archives-landsat-level-2-provisional-surface?qt-science_center_objects=0#qt-science_center_objects) taken from the USGS EarthExplorer repository’s Analysis Ready Data series. These were processed to derive mean, minimum, and maximum LST in degrees Fahrenheit for each Census block group based on the 30 x 30 meter grid cells from the source Landsat images that fall within the boundary of the block group. \n",
    "\n",
    "We also calculated the percentage of each block group comprised by the [land cover designations](https://www.mrlc.gov/data/legends/national-land-cover-database-2016-nlcd2016-legend) in the 2016 National Land Cover Database maintained by the U.S. Geological Survey (USGS). \n",
    "\n",
    "Finally, we collected tree canopy data for Washington, DC from [Open Data DC](https://opendata.dc.gov/datasets/DCGIS::urban-tree-canopy-2020/about). Some landscape metrics are already calculated from the tree canopy data and will be used in the modeling exercise here. You can find the details on landscape metrics [here](https://cran.r-project.org/web/packages/landscapemetrics/landscapemetrics.pdf). This exercise focuses on the machine learning modeling and not on data collection from satellite imagery or tree canopy data. Only curated data files are shared here without going to the details of data curation process.\n",
    "\n",
    "Before we dive into the modeling component, let's explore the data a little. \n",
    "\n",
    "The first code chunk is where we will load all the packages that we will need. **Please note** that you may need to install some of the packages below before you can load them with the `library` function. If you find any of the packages already not installed, uncomment (i.e., remove #) the install.packages command for that package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7ad08c-6dc6-4cfc-b582-da8ec3d87038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"caret\", repos=\"http://cran.r-project.org\")\n",
    "#install.packages(\"ggmap\", repos=\"http://cran.r-project.org\")\n",
    "#install.packages(\"rpart\", repos=\"http://cran.r-project.org\")\n",
    "#install.packages(\"rpart.plot\", repos=\"http://cran.r-project.org\")\n",
    "#install.packages(\"rsample\", repos=\"http://cran.r-project.org\")\n",
    "#install.packages(\"tidyverse\", repos=\"http://cran.r-project.org\")\n",
    "#install.packages(\"DataExplorer\")\n",
    "#install.packages(\"corrplot\")\n",
    "#install.packages(\"randomForest\")\n",
    "\n",
    "library(corrplot)\n",
    "library(ggplot2)\n",
    "library(caret)\n",
    "library(ggmap)\n",
    "library(rpart)\n",
    "library(rpart.plot)\n",
    "library(rsample)\n",
    "library(sf)\n",
    "library(tidyverse)\n",
    "library(DataExplorer)\n",
    "library(corrplot)\n",
    "library(ModelMetrics)\n",
    "library(randomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52c0358-e03d-4c52-b36d-0bd077c91faa",
   "metadata": {},
   "source": [
    "Now we will read the required data files. WashingtonDC.csv file contains data on land surface temperature, land cover, and different landscape metrics for tree canopy at the census block group level. The Cenesus Block Group map is saved as an **sf** object called `dc.bgs` which we will use for visualizing heat exposure, land cover, and tree canopy coverage in the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9df5a02-8a6c-42a3-8257-63a40fe2e178",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.data <- read.csv(\"data/WashingtonDC.csv\")\n",
    "dc.bgs <- st_read(\"data/WashingtondcBG2.shp\")\n",
    "head(dc.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb20b92-9a6d-4b25-816c-4615558918c7",
   "metadata": {},
   "source": [
    "Let's do some quick exploratory data analysis before proceeding. The following code chunk will create map for mean land surface temperature at census block group level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511bca61-dc2e-4ae1-b4fc-aa1ebd02aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DC basemap so we do not have to retrieve it from \n",
    "# the web (i.e., use a Google API key each time)\n",
    "\n",
    "load(file = \"data/dc_basemap.RData\")\n",
    "\n",
    "dc.bgs.wgs84 <- st_transform(dc.bgs, 4326)\n",
    "dc.bgs.wgs84 <- dc.bgs.wgs84 %>% mutate(GEOID.dbl = as.numeric(GEOID10))\n",
    "\n",
    "dc.bg.data.wgs84 <- full_join(dc.bgs.wgs84, dc.data, by = c(\"GEOID.dbl\" = \"GEOID\"))\n",
    "dc.bg.data.wgs84 <- st_transform(dc.bg.data.wgs84, 4326)\n",
    "\n",
    "# Recode NA to zero for NLCD variables\n",
    "dc.bg.data.wgs84 <- dc.bg.data.wgs84 %>% replace(is.na(.), 0)\n",
    "\n",
    "# Add categorical populations variable based on terciles\n",
    "dc.bg.data.wgs84 <- dc.bg.data.wgs84 %>% \n",
    "    filter(!is.na(TotPop)) %>%\n",
    "    mutate(Pop_Tercile = case_when(\n",
    "      TotPop < 1125 ~ \"Low\",\n",
    "      TotPop < 1700 & TotPop >= 1125 ~ \"Middle\",\n",
    "      TotPop >= 1700 ~ \"High\"))\n",
    "\n",
    "mean.lst.map <- ggmap(dc_basemap) +\n",
    "  geom_sf(data = dc.bg.data.wgs84, aes(fill = MeanF), alpha = 0.4, inherit.aes = FALSE) +\n",
    "    scale_fill_gradient(low = \"green\", high = \"red\") +\n",
    "    theme_classic() +\n",
    "    theme(axis.line = element_blank(), axis.text = element_blank(),\n",
    "        axis.ticks = element_blank(), axis.title = element_blank()) + \n",
    "    labs(fill = \"Mean LST °F\")\n",
    "\n",
    "mean.lst.map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536573bb-0325-4736-9644-257dc7d0b111",
   "metadata": {},
   "source": [
    "Now we will create maps for high intensity and medium intensity developments to visually compare them with temperature map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a7253-f7f7-4088-82bf-3eb7bbdff725",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.high.map <- ggmap(dc_basemap) +\n",
    "  geom_sf(data = dc.bg.data.wgs84, aes(fill = Dev_HighIntensity), alpha = 0.5, inherit.aes = FALSE) +\n",
    "    scale_fill_gradient(low = \"green\", high = \"purple\") +\n",
    "    theme_classic() +\n",
    "    theme(axis.line = element_blank(), axis.text = element_blank(),\n",
    "        axis.ticks = element_blank(), axis.title = element_blank()) + \n",
    "    labs(fill = \"% High Intensity Developed\")\n",
    "\n",
    "dev.med.map <- ggmap(dc_basemap) +\n",
    "  geom_sf(data = dc.bg.data.wgs84, aes(fill = Dev_MedIntensity), alpha = 0.5, inherit.aes = FALSE) +\n",
    "    scale_fill_gradient(low = \"green\", high = \"purple\") +\n",
    "    theme_classic() +\n",
    "    theme(axis.line = element_blank(), axis.text = element_blank(),\n",
    "        axis.ticks = element_blank(), axis.title = element_blank()) + \n",
    "    labs(fill = \"% Medium Intensity Developed\")\n",
    "\n",
    "dev.high.map\n",
    "dev.med.map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b56c24-b2c0-414f-8364-2d0357a8b178",
   "metadata": {},
   "source": [
    "Check out the variables available in the provided data. You will see that we have data on LST (MeanF, StdDevF, MinF, MaxF), along with tree canopy landscape metrics (ai, area_mn, etc.) and land cover classes (Dev_OpenSpace, Dev_LowIntensity, etc.) at the Block Group level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579347ea-d7f7-4546-a8db-cc09eb0ae0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(dc.bg.data.wgs84)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c36390-73b3-4dbd-909f-128167c2dfa3",
   "metadata": {},
   "source": [
    "Now we will create histograms of the LST variables and a correlation plot (or correlogram) for all continuous LST variables with average patch size \"area_mn\" of tree canopy. It shows a significant negative correlation between mean temperature (MeanF) and average patch size of tree canopies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0e1ea-fdcd-4876-8f0c-0c2d4c8f4cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(dc.bg.data.wgs84[ , 39:42])\n",
    "res <- cor(st_drop_geometry(dc.bg.data.wgs84[ , c(39:42, 19)]), use = \"pairwise.complete.obs\")\n",
    "round(res, 2)\n",
    "corrplot(res, type = \"upper\", order = \"hclust\", \n",
    "         tl.col = \"black\", tl.srt = 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93e1724-e92c-4916-9ce9-fa80286372a5",
   "metadata": {},
   "source": [
    "Following code chunks create plots showing the distribution of land surface temperature with high, medium, and low intensity development, and how mean patch size of tree canopy are distributed at census block group level. You will see how the size of tree canopy varies by development intensity at the block group level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f1dbf6-ee19-44f0-b669-56ab71c114e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "high.dev.lst.plot <- dc.bg.data.wgs84 %>%\n",
    "  filter(!is.na(Dev_HighIntensity)) %>%\n",
    "  ggplot(aes(x = MeanF, y = Dev_HighIntensity)) + \n",
    "  geom_point(aes(size = area_mn), color=\"red\", alpha = 0.4) +\n",
    "  geom_smooth(method=lm, se=FALSE, color = \"purple\", linetype=\"dashed\") +\n",
    "  theme_minimal() +\n",
    "  labs(title = \"\", x = \"Mean LST °F\", y = \"% High Intensity Developed\", size = \"Mean Patch \n",
    "       Size\") \n",
    "\n",
    "high.dev.lst.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec23208-21a7-4178-8628-27378c388c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "med.dev.lst.plot <- dc.bg.data.wgs84 %>%\n",
    "  filter(!is.na(Dev_MedIntensity)) %>%\n",
    "  ggplot(aes(x = MeanF, y = Dev_MedIntensity)) + \n",
    "  geom_point(aes(size = area_mn), color = \"#009E73\", alpha = 0.4) +\n",
    "  geom_smooth(method=lm, se=FALSE, color = \"purple\", linetype=\"dashed\") +\n",
    "  theme_minimal() +\n",
    "  labs(title = \"\", x = \"Mean LST °F\", y = \"% Medium Intensity Developed\", size = \"Mean Patch \n",
    "       Size\") \n",
    "\n",
    "med.dev.lst.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed1e499-5b5d-4bad-b327-b2bee21a6f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "low.dev.lst.plot <- dc.bg.data.wgs84 %>%\n",
    "  filter(!is.na(Dev_LowIntensity)) %>%\n",
    "  ggplot(aes(x = MeanF, y = Dev_LowIntensity)) + \n",
    "  geom_point(aes(size = area_mn), color = \"steelblue\", alpha = 0.4) +\n",
    "  geom_smooth(method=lm, se=FALSE, color = \"purple\", linetype=\"dashed\") +\n",
    "  theme_minimal() +\n",
    "  labs(title = \"\", x = \"Mean LST °F\", y = \"% Low Intensity Developed\", size = \"Mean Patch \n",
    "       Size\") \n",
    "\n",
    "low.dev.lst.plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632b201c-71a1-4a55-ab5b-897474147a82",
   "metadata": {},
   "source": [
    "Let's look at the summary statistics and histogram for all continuous landscape variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c999cb-a9bb-4d02-a174-bf97e97e5f5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary((dc.bg.data.wgs84[18:29]))\n",
    "plot_histogram(dc.bg.data.wgs84[ , 18:29])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec5637a-0adf-4fa4-ba71-b45261e1a896",
   "metadata": {},
   "source": [
    "We can create a correlation matrix and correlogram of all the landscape metrics and mean LST to see which tree canopy landscape variables are significantly correlated with LST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e65319-dfde-4a0b-98cd-e76b891fa779",
   "metadata": {},
   "outputs": [],
   "source": [
    "res <- cor(st_drop_geometry(dc.bg.data.wgs84[ , c(17:21, 23:33, 39)]), use = \"pairwise.complete.obs\")\n",
    "round(res, 2)\n",
    "corrplot(res, type = \"upper\", order = \"hclust\", \n",
    "         tl.col = \"black\", tl.srt = 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb04b497-3d1b-4501-b54c-bb9675acec60",
   "metadata": {},
   "source": [
    "The landscape metric correlation matrix plot shows most of the landscape metrics are negatively correlated with mean LST, but it also shows a positive relationship between mean LST and: (1) the landscape division index \"division\", (2) patch density \"pd\", and (3) the splitting index \"split\".\n",
    "\n",
    "[Patch density](https://r-spatialecology.github.io/landscapemetrics/reference/lsm_l_pd.html) measures the fragmentation of tree canopy in the block group, while [division](https://r-spatialecology.github.io/landscapemetrics/reference/lsm_l_division.html) captures evenness of distribution across block groups. The [splitting index](https://r-spatialecology.github.io/landscapemetrics/reference/lsm_l_split.html) reflects variation in the size of patches. \n",
    "\n",
    "So, as fragmentation of tree canopy **(r = 0.72)**, unequal distribution of tree canopy **(r = 0.72)**, and the variation in the size of tree canopy patches **(r = 0.48)** increase, mean land surface temperature also increases. \n",
    "\n",
    "Mean LST has the highest negative relationship with: (1) average patch size \"area_mn\", (2) the aggregation index \"ai\", (3) patch cohesion index \"cohesion\", and (4) largest patch index \"lpi\". \n",
    "\n",
    "[Average patch size](https://r-spatialecology.github.io/landscapemetrics/reference/lsm_l_area_mn.html) is self-explanatory, the [aggregation index](https://link.springer.com/article/10.1023/A:1008102521322) and the [cohesion index](https://r-spatialecology.github.io/landscapemetrics/reference/lsm_l_cohesion.html) are measures of connectivity and compactness, and the [largest patch index](https://r-spatialecology.github.io/landscapemetrics/reference/lsm_l_lpi.html) is the percentage of the block group covered by the largest patch of tree canopy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634b9bf-72f6-4b2d-a37c-6e1d26b30de0",
   "metadata": {},
   "source": [
    "*As the size and connectivity of tree canopy patches increases, mean land surface temperature decreases.* We can see this effect (i.e., mean tree canopy patch size) in the scatterplots generated by the code block above. The relationship between block group population and mean LST is weak **(r = 0.08)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3b44c-8f9a-41e4-8aad-584d7d0704ac",
   "metadata": {},
   "source": [
    "Now that we have a feel for the distribution of LST and developed land uses from the NLCD data shown in the maps generated by the code block above, we can turn our attention to fitting models. We will begin with a quick look at the K-Nearest Neighbors technique for predicting the mean land surface temperature at the Census block group level in Washington DC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2f5e5b-84f5-4f6f-98a9-86097a095931",
   "metadata": {},
   "source": [
    "## Fitting K-Nearest Neighbors Regression Models\n",
    "\n",
    "As described in more detail here the [K-Nearest neighbors algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) is one of the simplest prediction techniques out there. If we are trying to predict a categorical (qualitative) outcome or dependent variable, we are fitting a **classification** model. In these instances, the algorithm: \n",
    "\n",
    "  + Identifies K observations that have similar characteristics (e.g., independent variables)\n",
    "  + Determines the majority (most common) class for those K similar observations and assigns that class as the predicted outcome\n",
    "<br> \n",
    "\n",
    "If we are trying to predict a continuous (quantitative) outcome or dependent variable, we are fitting a **regression** model. In these instances, the algorithm: \n",
    "\n",
    "  + Identifies K observations that have similar characteristics (e.g., independent variables)\n",
    "  + Determines the mean of the dependent variable values for those K similar observations and assigns that value as the predicted outcome\n",
    "<br> \n",
    "\n",
    "\n",
    "In the code chunk below, we use the `set.seed` function to assign a starting value to the random number generator built into R so that we can replicate the analysis later.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd222d4-a17f-45bc-9b8e-459167bf7cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(227)\n",
    "\n",
    "dc.bg.data.no.geom <- st_drop_geometry(dc.bg.data.wgs84)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13dcd9e-d3ac-49b3-9100-c839df04bd7d",
   "metadata": {},
   "source": [
    "Now we will partition the data to training and testing sets using initial_split() function of rsample package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472c66f-bcf8-4b10-8dde-b95f17d8b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.bg.data.wgs84.split <- initial_split(dc.bg.data.no.geom, prop = 0.7)\n",
    "dc.bg.data.wgs84.train <- training(dc.bg.data.wgs84.split)\n",
    "dc.bg.data.wgs84.test  <- testing(dc.bg.data.wgs84.split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe2b03c-d648-4abd-9129-6e85de9c0ceb",
   "metadata": {},
   "source": [
    "We will extract the labels so that we can reattach predicted values to geometry later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9444b8d-aacc-40e4-b464-304c2908d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.labels <- as.numeric(unlist(labels(dc.bg.data.wgs84.train)[1]))\n",
    "test.labels <- as.numeric(unlist(labels(dc.bg.data.wgs84.test)[1]))\n",
    "\n",
    "dc.train.bgs <- dc.bg.data.wgs84[train.labels, ]\n",
    "dc.test.bgs <- dc.bg.data.wgs84[test.labels, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be71905-146a-4005-8be4-c045602392e0",
   "metadata": {},
   "source": [
    "Next, we will choose the variables we want to use for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aec623-cd67-4c8a-b8a9-ddd69ad7db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dc.bg.data.wgs84.test <- subset(dc.bg.data.wgs84.test, select = c(\"MeanF\", \"TotPop\", \"ai\", \"area_mn\", \"cohesion\", \n",
    "                                                                  \"lpi\", \"division\", \"pd\", \"split\", \n",
    "                                                                  \"Water\", \"Dev_OpenSpace\", \"Grassland\"))\n",
    "\n",
    "dc.bg.data.wgs84.train <- subset(dc.bg.data.wgs84.train, select = c(\"MeanF\", \"TotPop\", \"ai\", \"area_mn\", \"cohesion\", \n",
    "                                                                    \"lpi\", \"division\", \"pd\", \"split\", \n",
    "                                                                    \"Water\", \"Dev_OpenSpace\", \"Grassland\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7687ac-ebbd-4b0b-92a9-19966c2667cc",
   "metadata": {},
   "source": [
    "For regression (i.e., continuous dependent variables), the KNN algorithm finds the K observations most like a given new observation in terms of its characteristics (independent variables) and assigns the mean of the dependent variable values of those neighbors to the new observation for which we are making a prediction.\n",
    "\n",
    "In the code chunk below, we will use the **caret** package to fit a regression model using the KNN algorithm where the outcome is mean land surface temperature at the Census block group level. Performing K-Nearest Neighbors regression with the **caret** package has a few advantages including: (1) that it automatically tests various values of K for us, (2) it chooses the value of K that minimizes cross-validation error, and (3) fits the final, best-fitting model to the data. However, before running the code chunk below, take a look at the help documentation for the `caret::train` and the `caret::trainControl` functions. \n",
    "\n",
    "<br> \n",
    "\n",
    "The `trainControl` function can be accessed directly or from within the `train` function via the `trControl` argument. In the example below we are setting up [10-fold cross-validation](https://towardsdatascience.com/why-and-how-to-cross-validate-a-model-d6424b45261f) which happens to be one of the more commonly used. This means the algorithm will use 90 percent of the data to create a model and 10 percent to test it. Then, we will run the model again with a different 10 percent and repeat this 10 times, until all the data has been used as both training and test data. \n",
    "\n",
    "The `preProcess` argument can be used to scale, center, or otherwise transform the input data. The `tuneLength` parameter tells the algorithm to try different default values and the `tuneGrid` parameter lets us decide which values the main parameter will take: `tuneGrid = expand.grid(k = c(5, 11, 21, 25))`. This is how you could fit a different model than the \"best-fitting\" one identified by the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c9b40-8729-4e63-a96a-cf92ca1e6d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set options for the cross-validation routine with 10-folds\n",
    "ctrl <- trainControl(method=\"cv\", number = 10)\n",
    "\n",
    "# Fit the model...\n",
    "knnFit.value <- train(MeanF ~ .,\n",
    "                data = dc.bg.data.wgs84.train, method = \"knn\", trControl = ctrl,\n",
    "                preProcess = c(\"center\",\"scale\"), tuneLength = 30)\n",
    "\n",
    "# Examine the output\n",
    "knnFit.value\n",
    "plot(knnFit.value)\n",
    "\n",
    "# Try again using a different resampling method where\n",
    "# 10-folds are repeated 3 times\n",
    "ctrl <- trainControl(method=\"repeatedcv\", repeats = 3)\n",
    "knnFit.value <- train(MeanF ~ ., \n",
    "                data = dc.bg.data.wgs84.train, method = \"knn\", trControl = ctrl, \n",
    "                preProcess = c(\"center\",\"scale\"), tuneLength = 30)\n",
    "knnFit.value\n",
    "plot(knnFit.value)\n",
    "\n",
    "get_best_result = function(caret_fit) {\n",
    "  best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))\n",
    "  best_result = caret_fit$results[best, ]\n",
    "  rownames(best_result) = NULL\n",
    "  best_result\n",
    "}\n",
    "\n",
    "get_best_result(knnFit.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522c529b-5a67-43c3-b3b0-797cfef5ae7a",
   "metadata": {},
   "source": [
    "We can more or less tell at which value of K the overall accuracy peaks (i.e., RMSE is lowest) from the graphic shown above. However, we can also retrieve this value directly and use it to predict mean LST for the test set we created before. The latter portions of the code below are [taken from this post](http://zevross.com/blog/2017/09/19/predictive-modeling-and-machine-learning-in-r-with-the-caret-package) and may be a useful reference. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6400f8-ac39-4dfb-963f-e4ef2c534b77",
   "metadata": {},
   "source": [
    "Print the best tuning parameter k that maximizes model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aba5cb-8e2e-4823-8150-e39a81e71838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knnFit.value$bestTune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068e123f-7cb5-4c27-b6f2-0991ca7fbeb2",
   "metadata": {},
   "source": [
    "Now use the best fitting model to predict mean LST for the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569d92f-8927-42fc-8595-109762003722",
   "metadata": {},
   "outputs": [],
   "source": [
    "knnPredict.value <- predict(knnFit.value, newdata = dc.bg.data.wgs84.test)\n",
    "plot(knnPredict.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305d2755-cc72-47bf-8be9-8d511c73ef7a",
   "metadata": {},
   "source": [
    "Now we can calculate RMSE between actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87016c7c-fe12-40a1-b33f-818abd8b57d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(predicted = knnPredict.value, actual = dc.bg.data.wgs84.test$MeanF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b8730-a298-4cc6-b93a-74ff1aceed2c",
   "metadata": {},
   "source": [
    "We can also compare OLS and random forest models. The following code chunk will compare the results from OLS, random forest, and KNN models. We will also check if the differences are statisticaly significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d060b5b-6984-4c46-b625-fbe183045b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.value <- train(MeanF ~., data = dc.bg.data.wgs84.train, method = \"lm\")\n",
    "rf.value <- train(MeanF ~., data = dc.bg.data.wgs84.train, method = \"rf\")\n",
    "knn.value <- train(MeanF ~ ., data = dc.bg.data.wgs84.train, method = \"knn\")\n",
    "\n",
    "# Compare models\n",
    "model_list <- list(lm = lm.value, rf = rf.value, knn = knn.value)\n",
    "res <- resamples(model_list)\n",
    "summary(res)\n",
    "\n",
    "compare_models(lm.value, rf.value)\n",
    "compare_models(rf.value, knn.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bc1a51-4b0e-4f16-8cf5-808502618692",
   "metadata": {},
   "source": [
    "### Fitting Regression Tree Models \n",
    "\n",
    "The KNN approach is simplistic, but its results are often used as input (i.e., another independent variable) to more sophisticated models. Next, let's use the **rpart** package to fit **tree** models to our data. You can learn more about Regression Tree and other Decision Tree approaches for machine learning [here](https://www.datacamp.com/tutorial/decision-trees-R). Take a few moments to review the help documentation for the `rpart` and the `rpart.object` functions available [here](https://cran.r-project.org/web/packages/rpart/rpart.pdf), then proceed with the code chunk below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2bc023-2379-45fa-9c77-af346eea2182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Because our dependent variable is continuous, we set \n",
    "# the methods argument to \"anova\" for regression...\n",
    "model.lst <- rpart(\n",
    "  formula = MeanF ~ .,\n",
    "  data    = dc.bg.data.wgs84.train,\n",
    "  method  = \"anova\", \n",
    "  minsplit = 4, \n",
    "  minbucket = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f83bca-9f8f-41db-ae8e-2dd8feba5b7d",
   "metadata": {},
   "source": [
    "Let's examine the output in both text and visual format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962b9d76-5900-41bb-986e-b25df5cc392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lst\n",
    "rpart.plot(model.lst, box.palette = \"GnYlRd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eff1ae-9e86-49af-8f30-18baa2c38951",
   "metadata": {},
   "source": [
    "We can also retrieve more detailed info about the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f4dd0-abae-4f72-9d64-52869927275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model.lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca39cd65-2feb-4e6c-be46-e70e70b243c0",
   "metadata": {},
   "source": [
    "We can also display the model's frame attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb1c308-2b2a-4d03-9532-4cc24ad03da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lst$frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1415493f-55b7-4bc8-8ae3-10d9b1dbbdf3",
   "metadata": {},
   "source": [
    "In this simple model, we begin with 315 observations in the training set and there are five internal nodes and six terminal nodes or leaves. As we move down the tree, the plot communicates which independent variables were chosen for splits, the values of those independent variables that optimized the split criterion (e.g., [**Gini impurity**](https://blog.quantinsti.com/gini-index/)), the average value of the independent variable in question at each node, and the percentage of the observations that \"flow\" to each node. \n",
    "\n",
    "As shown above, typing the name of the **rpart object** displays model information that mirrors what we see in the tree plot, but in text form. Note how the depth of the indent reflects the structure of the (plotted) tree. These are the elements shown above: \n",
    "    + node: a unique number for the node in the tree\n",
    "    + split: the equation used to branch at the node\n",
    "    + n: number of observations that \"flow\" through that branch\n",
    "    + deviance (for regression): the deviance associated with that branch \n",
    "    + yval: predicted value at the node\n",
    "    + *: an asterisk next to a node indicates it is terminal\n",
    "\n",
    "Applying the `summary` function to an **rpart object** displays more detailed information. As shown in the documentation for the `rpart.object` function, the frame attribute of an rpart object (i.e., **model.lst$frame**) is a \"data frame with one row for each node in the tree.\" The **var** column lists variables used at each split, **n** is the number of observations reaching that node, **wt** is the sum of of case weights (1 by default) for observations reaching that node, **dev** is the deviance which is a goodness of fit statistic that equals the sum of squared residuals for linear models. The **yval** column is the fitted value of the dependent variable at the node, **complexity** is the complexity parameter at which this split will collapse, **ncompete** is the number of competitor splits recorded, and **nsurrogate** is the number of surrogate splits recorded. \n",
    "\n",
    "Surrogate variables are used when a value is missing and so a split cannot be completed with the main variable. A surrogate is a different variable that is chosen to approximate the first-choice variable in a split. \n",
    "\n",
    "We can retrieve the **cp** value for the model and set it to a value above the threshold for the second **area_mn** split to demonstrate its effects like this: `model.lst$control$cp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0cfb9d-18ee-4d87-9530-58df14703db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune the model...\n",
    "model.pruned <- prune(model.lst, cp = 0.02)\n",
    "model.pruned$frame\n",
    "rpart.plot(model.pruned, box.palette = \"GnYlRd\")\n",
    "\n",
    "\n",
    "# We could also set this parameter explicitly and rerun the model: \n",
    "temp <- rpart.control(cp = 0.02)\n",
    "model.lst.2 <- rpart(\n",
    "  formula = MeanF ~ .,\n",
    "  data    = dc.bg.data.wgs84.train,\n",
    "  method  = \"anova\",\n",
    "  control = temp\n",
    ")\n",
    "\n",
    "model.lst.2$frame\n",
    "rpart.plot(model.lst.2, box.palette = \"GnYlRd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95670c5f-aff7-4af0-8090-795cf9f5c1e2",
   "metadata": {},
   "source": [
    "According to the `rpart.object` documentation, the **cp table** is *\"a matrix of information on the optimal prunings based on a complexity parameter\"*. Behind the scenes `rpart` is automatically applying an array of cost complexity values to prune the tree. The **CP** column is the value of this parameter that would grow the tree to this size. The **nsplit** column is the number of nodes at that size, **rel error** is the error for predictions of the data that were used to estimate the model, while **xerror** is the cross-validation error generated by the `rpart` built-in cross validation routine and **xstd** gives us a sense of its variability over the default 10 iterations (see `plotcp`). Also note that (1 - relative error) is roughly equal to the variance explained by the model.\n",
    "\n",
    "The **CP** values control the size of the tree and the greater the **CP** value, the fewer the number of splits in the tree. The optimal size of the tree is generally the row in the **CP table** that minimizes all error with the fewest branches. \n",
    "\n",
    "In the plot below, the dotted line refers to a recommendation from [Breiman et al. (1984)](https://www.taylorfrancis.com/books/mono/10.1201/9781315139470/classification-regression-trees-leo-breiman-jerome-friedman-olshen-charles-stone) to use the smallest tree within 1 standard deviation of the minimum cross validation error. You can think about the complexity parameter as the amount by which splitting that node improved the relative error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceaeb69-1584-4281-bf02-58923f1f23d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lst$cptable\n",
    "plotcp(model.lst)\n",
    "\n",
    "model.lst$splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907026a9-2e60-43cc-8a17-9b62efc68118",
   "metadata": {},
   "source": [
    "The splits attribute consists of a row label which is the name of the split variable, and the rest of the columns are **count**, the number of observations sent left or right by the split (for competitor splits this is the number that would have been sent left or right had this split been used, for surrogate splits it is the number missing the primary split variable which were decided using this surrogate), **ncat** which is the number of categories or levels for the variable (+/-1 for a continuous variable), **improve** which is the improvement in deviance given by this split, or, for surrogates, the concordance of the surrogate with the primary, and **index**, the numeric split point. The last column **adj** gives the adjusted concordance for surrogate splits. For a continuous variable, the sign of **ncat** determines whether the subset x < cutpoint or x > cutpoint is sent to the left. \n",
    "\n",
    "A case weight is a nonnegative numeric variable that indicates the importance of each case. There are three types of case weights: frequencies, sampling weights, and variance weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0438dcc2-e218-4d23-8e48-029c8a41f74e",
   "metadata": {},
   "source": [
    "Now we will use Regression Tree model for Prediction and check out the RMSE value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5417b05-89ce-4f62-8502-1b37f80116d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lst.pred <-  predict(model.lst, newdata = dc.bg.data.wgs84.test)\n",
    "\n",
    "caret::RMSE(pred = model.lst.pred, obs = dc.bg.data.wgs84.test$MeanF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908208c4-40ad-4945-89fa-857261a9517e",
   "metadata": {},
   "source": [
    "Now we will create a couple of plots to compare the predicted values to the observed values (i.e., from the satellite imagery)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b9f729-7570-4e93-859e-65c11846bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.test.bgs$rtpred <- model.lst.pred\n",
    "\n",
    "fitted <- ggplot() +\n",
    "  geom_sf(data = dc.test.bgs, aes(fill = rtpred)) + theme_void() + \n",
    "  scale_fill_gradient(low = \"yellow\", high = \"red\") + \n",
    "  labs(title = \"Predicted LST\") + \n",
    "  theme(plot.title = element_text(hjust = 0.5))\n",
    "\n",
    "fitted\n",
    "\n",
    "observed <- ggplot() +\n",
    "  geom_sf(data = dc.test.bgs, aes(fill = MeanF)) + theme_void() + \n",
    "  scale_fill_gradient(low = \"yellow\", high = \"red\") + \n",
    "  labs(title = \"Satellite LST\", fill = \"Land Surface Temperature °F\") +\n",
    "  theme(plot.title = element_text(hjust = 0.5))\n",
    "\n",
    "observed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7531a35e-aeb1-420f-97fd-0de9d303d067",
   "metadata": {},
   "source": [
    "We can also map the residuals to see where the model is performing poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b1fced-e151-4bb7-a6f7-9905f83485e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.test.bgs$rtresid <- dc.test.bgs$MeanF - dc.test.bgs$rtpred\n",
    "\n",
    "the.diff <- ggplot() +\n",
    "  geom_sf(data = dc.test.bgs, aes(fill = rtresid)) + theme_void() + \n",
    "  scale_fill_gradient(low = \"green\", high = \"red\") + \n",
    "  labs(title = \"Difference in Satellite and Predicted LST\", fill = \"°F\") +\n",
    "  theme(plot.title = element_text(hjust = 0.5),\n",
    "        plot.margin = unit(c(1, 1, 2, 1), unit = \"cm\"))\n",
    "\n",
    "the.diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d7c99-6d45-4b2a-9326-2e4da8731706",
   "metadata": {},
   "source": [
    "Based on the results from the above code chunk, this model does not fit the validation set **super** well. We could modify the predictors (independent variables) to try and improve our predictive capacity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f0a84b-d3b9-4dd1-b70b-56d5d71bc0bf",
   "metadata": {},
   "source": [
    "We can also try other machine learning modeling approach for this analysis. The work of [Wilson et al. (2024)](https://journals.sagepub.com/doi/abs/10.1177/23998083241226848) is an example that modeled the relationship between urban tree canopy, landscape heterogeneity, and land surface temperature using Generalized Boosted Regression Model (GBM). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d0abe5-0f29-497e-934f-bc23a8c52ee6",
   "metadata": {},
   "source": [
    "<b> Reflection and challenge tasks </b>\n",
    "\n",
    "This exercise shows several examples of machine learning approach to model the relationship between land surface temperature and tree canopy landscape metrices. It also shows how to compare the model results. This exercise can be further expanded by modeling data for another city (as done in [Wilson et al. (2024)](https://journals.sagepub.com/doi/abs/10.1177/23998083241226848)) or trying out different variable combinations for tree canopy metrics and land use classes as shared in the data files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iguide-ewd-r",
   "language": "R",
   "name": "iguide-ewd-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
